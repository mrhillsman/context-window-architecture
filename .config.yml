# db is the top-level key used to provide two objects for
# creating a sqlite3 database and chromadb vector database
db:
  sql:
    dir: "db"
    file: "store.db"
  vector:
    dir: "db"
    file: "vectordb"

# use local ollama service
ollama:
  enabled: true
  host: "http://localhost:11434"
  chat_model: "llama3.2:3b-instruct-fp16"
  agent_model: "deepseek-r1:8b"
  options:
    temperature: 0.1

# llm_config is the top-level key used throughout the project
# for configuring the LLMs used and their hyperparameters
llm_config:
  chat_model: "gemini-2.5-flash-preview-05-20"
  summary_model: "gemini-2.0-flash"
  rag_model: "gemini-2.0-flash"
  temperature: 0.0

# chat_history_config is the top-level key for configuring
# the strategy for managing the chat history
chat_history_config:
  # max_history_pairs limits the number of multi-turn conversations
  # in the chat history; this also helps with summarization allowing
  # summarization to be triggered once max_history_pairs is reached
  max_history_pairs: 2
  # max_characters strategy to limit history based on the number of characters
  max_characters: 1000
  # max_tokens strategy to limit history based on the number of tokens
  max_tokens: 2000

# agent_config is the top-level key for configuring agents throughout the project
agent_config:
  max_function_calls: 3

# vectordb_config is the top-level key for configuring the chroma vector database
vectordb_config:
  collection_name: "chat_history"
  embedding_model: "gemini-embedding-exp"
  k: 5

# oauth_config is the top-level key for configuring OAuth authentication
oauth_config:
  enabled: true
  provider: "google"
  # set client_id and client_secret in .env file using GOOGLE_CLIENT_ID and GOOGLE_CLIENT_SECRET
  client_id: ""
  client_secret: ""
  redirect_uri: "http://localhost:8501"
  scope: "openid email profile"
  auth_endpoint: "https://accounts.google.com/o/oauth2/v2/auth"
  token_endpoint: "https://oauth2.googleapis.com/token"
  userinfo_endpoint: "https://www.googleapis.com/oauth2/v3/userinfo"

# chatbot determines the chatbot loaded during project execution
chatbot:
  # type: "basic"
  type: "basic_memory"
  # type: "agentic"
  # type: "semantic"
  # type: "langgraph"
  # type: "letta"

chatbot_configs:
  basic:
    page:
      title: ""
      icon: ""
      layout: ""